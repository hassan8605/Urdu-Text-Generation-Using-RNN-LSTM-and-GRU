{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvHFEuroztXu"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow pandas matplotlib openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import os"
      ],
      "metadata": {
        "id": "GDDK4EbQ1bOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/dl/Urdu Corpus.xlsx\""
      ],
      "metadata": {
        "id": "Rqlnvs0O1eg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(file_path)\n",
        "df.dropna(inplace=True)\n",
        "sentences = df[\"Text Lines\"].astype(str).tolist()"
      ],
      "metadata": {
        "id": "b0xHdCBy1ns7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "OIy-IHPv1s5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(char_level=True, filters='')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "total_chars = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "z_LNG2Pz1rMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input Sequences**"
      ],
      "metadata": {
        "id": "u1J7-yT11xo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_seq = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_seq)\n",
        "\n",
        "input_sequences = input_sequences[:100000]\n",
        "\n",
        "# Then compute max length on trimmed data\n",
        "max_seq_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n",
        "\n",
        "# Use only sparse labels (save memory)\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "XbtU65pO1v2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Builder**"
      ],
      "metadata": {
        "id": "f85h8mUBWytx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def build_model(model_type):\n",
        "#     model = Sequential()\n",
        "#     model.add(Embedding(input_dim=total_chars, output_dim=50, input_length=max_seq_len - 1))\n",
        "#     if model_type == \"RNN\":\n",
        "#         model.add(SimpleRNN(128))\n",
        "#     elif model_type == \"LSTM\":\n",
        "#         model.add(LSTM(128))\n",
        "#     elif model_type == \"GRU\":\n",
        "#         model.add(GRU(128))\n",
        "#     model.add(Dense(total_chars, activation='softmax'))\n",
        "#     model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#     return model"
      ],
      "metadata": {
        "id": "mtTHhEOyWz0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(model_type):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=total_chars, output_dim=50, input_length=max_seq_len - 1))\n",
        "    if model_type == \"LSTM\":\n",
        "        model.add(LSTM(128))\n",
        "    elif model_type == \"GRU\":\n",
        "        model.add(GRU(128))\n",
        "    model.add(Dense(total_chars, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "stpZ__q2y98b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and Save All Models**"
      ],
      "metadata": {
        "id": "HJvzHadxW235"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"/content/drive/MyDrive/dl/UrduTextGenModels\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "ubsZo6fzW35R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this i comment this because i did this for rnn"
      ],
      "metadata": {
        "id": "McbnbUHVzV_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# histories = {}\n",
        "# for model_name in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
        "#     print(f\"\\nTraining {model_name}...\")\n",
        "#     model = build_model(model_name)\n",
        "#     history = model.fit(X, y, epochs=10, verbose=1)\n",
        "#     histories[model_name] = history\n",
        "#     model.save(f\"{save_dir}/{model_name}_urdu_textgen.h5\")"
      ],
      "metadata": {
        "id": "izXgQMhKzDyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR LSTM**"
      ],
      "metadata": {
        "id": "kmxgqygvzdZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histories = {}\n",
        "for model_name in [\"LSTM\"]:\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    model = build_model(model_name)\n",
        "    history = model.fit(X, y, epochs=10, verbose=1)\n",
        "    histories[model_name] = history\n",
        "    model.save(f\"{save_dir}/{model_name}_urdu_textgen.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w87senfdXBq6",
        "outputId": "3f6b2c03-6620-47e8-d8f3-2c1941316e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LSTM...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 123ms/step - accuracy: 0.2684 - loss: 2.8766\n",
            "Epoch 2/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 124ms/step - accuracy: 0.3520 - loss: 2.3809\n",
            "Epoch 3/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 123ms/step - accuracy: 0.3847 - loss: 2.2374\n",
            "Epoch 4/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 123ms/step - accuracy: 0.4062 - loss: 2.1476\n",
            "Epoch 5/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 124ms/step - accuracy: 0.4195 - loss: 2.0861\n",
            "Epoch 6/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 123ms/step - accuracy: 0.4340 - loss: 2.0297\n",
            "Epoch 7/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 124ms/step - accuracy: 0.4470 - loss: 1.9824\n",
            "Epoch 8/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 123ms/step - accuracy: 0.4591 - loss: 1.9345\n",
            "Epoch 9/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 124ms/step - accuracy: 0.4639 - loss: 1.9081\n",
            "Epoch 10/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 123ms/step - accuracy: 0.4699 - loss: 1.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for GRU**"
      ],
      "metadata": {
        "id": "nMpUnCyqQGe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histories = {}\n",
        "for model_name in [\"GRU\"]:\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    model = build_model(model_name)\n",
        "    history = model.fit(X, y, epochs=10, verbose=1)\n",
        "    histories[model_name] = history\n",
        "    model.save(f\"{save_dir}/{model_name}_urdu_textgen.h5\")"
      ],
      "metadata": {
        "id": "szJ2tIFMXDak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c18ddaf-09d2-4644-c07b-2f8a7d97f800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training GRU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 126ms/step - accuracy: 0.2846 - loss: 2.7993\n",
            "Epoch 2/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 126ms/step - accuracy: 0.3782 - loss: 2.2671\n",
            "Epoch 3/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 126ms/step - accuracy: 0.4151 - loss: 2.1155\n",
            "Epoch 4/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 126ms/step - accuracy: 0.4373 - loss: 2.0200\n",
            "Epoch 5/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 126ms/step - accuracy: 0.4571 - loss: 1.9371\n",
            "Epoch 6/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 126ms/step - accuracy: 0.4704 - loss: 1.8784\n",
            "Epoch 7/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 126ms/step - accuracy: 0.4865 - loss: 1.8233\n",
            "Epoch 8/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 125ms/step - accuracy: 0.4930 - loss: 1.7947\n",
            "Epoch 9/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 125ms/step - accuracy: 0.5031 - loss: 1.7485\n",
            "Epoch 10/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 125ms/step - accuracy: 0.5103 - loss: 1.7152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Generation Function**"
      ],
      "metadata": {
        "id": "nnWS5eJ9UY82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, model, next_chars=100, temperature=1.0):\n",
        "    for _ in range(next_chars):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_seq_len - 1, padding='pre')\n",
        "        predictions = model.predict(token_list, verbose=0)[0]\n",
        "        predictions = np.log(predictions + 1e-9) / temperature\n",
        "        exp_preds = np.exp(predictions)\n",
        "        predictions = exp_preds / np.sum(exp_preds)\n",
        "        predicted_id = np.random.choice(len(predictions), p=predictions)\n",
        "        output_char = tokenizer.index_word.get(predicted_id, '')\n",
        "        seed_text += output_char\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "dlr4fq1rTTYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
        "    model = tf.keras.models.load_model(f\"{save_dir}/{model_name}_urdu_textgen.h5\")\n",
        "    print(f\"\\nText generated by {model_name}:\")\n",
        "    print(generate_text(\"پاکستان\", model, next_chars=200, temperature=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGFsXghmUjW6",
        "outputId": "70abd442-312f-4cf5-8f1e-f45ecf6f151a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text generated by RNN:\n",
            "پاکستان کا دے دیتے ہے۔ مشکواریف ککے جان نہیں فرنا بھی اسے لاتھ کی جین پیدا ہے کہ سکتی نکلے میں الاد دینٹی آثا ہے ان بحدیدات میں جاتا ہے اس شعر وصل کی گرد بڑازی نہیں ہے۔ روز پر کاران صطبوات کو محمد میں اعملات\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text generated by LSTM:\n",
            "پاکستانی سے منقف کے سلسدات ہو۔ کہا اور چائے ہوئے وہاں یہ رہا ہے۔ ازرجر تمدہ کا محاند پر حمانیت نے بعد حالیہ ہوجاتایا 70 روز نے نوب بنائی کی چیورزانی صلاعیا ہے۔ پیسٹز شدار منکا کے خلاحبار ، میں نکار بت کے لئے\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text generated by GRU:\n",
            "پاکستان اور کوستے دھوڑے رہے۔ ہم اسکے نیوالی آباعظمیرٹ کوشنائیں کے ملابق بازاروں کے انتخائد کے ردازہ بالیسولی کے طرل کیا تھی۔ شاہد لیکن ریاپتی 75ڈار کویاری کے نئے بات بالکے جائے گا۔ جائیں۔ دہشت گیا تک کوئی ک\n"
          ]
        }
      ]
    }
  ]
}